{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jsonschema import draft6_format_checker, draft7_format_checker\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import words\n",
    "from stop_words import get_stop_words\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def remove_stopwords(txt):\n",
    "    \n",
    "    sentence = []\n",
    "    s = \"\"\n",
    "    for word in txt.split():    \n",
    "        if(word not in stop_words):      \n",
    "            sentence.append(word)\n",
    "            s = ' '.join(sentence)\n",
    "    return s\n",
    "\n",
    "def strip_emoji(text):\n",
    "\n",
    "    print(emoji.emoji_count(text))\n",
    "\n",
    "    new_text = re.sub(emoji.get_emoji_regexp(), r\"\", text)\n",
    "\n",
    "    return new_text\n",
    "\n",
    "## Creating sentimental polarity \n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "def compound_score(txt):\n",
    "    return analyzer.polarity_scores(txt)[\"compound\"]\n",
    "\n",
    "## Sentiments\n",
    "def sentiment(score):\n",
    "    emotion = \"\"\n",
    "    if score >= 0.5:\n",
    "        emotion = \"Positive\"\n",
    "    elif score <= -0.5:\n",
    "        emotion = \"Negative\"\n",
    "    else:\n",
    "        emotion = \"Neutral\"\n",
    "    return emotion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 Merge Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "atm_data = []\n",
    "header_list = [\"Date\", \"Rating\", \"Title\",\"Review\",\"Name\",\"Geolocation\"]\n",
    "\n",
    "files = Path(\"input_data/\").rglob(\"*.csv\") #Input Folder ที่ทำการ Rename เรียบร้อยแล้ว\n",
    "\n",
    "for i in files:\n",
    "    df = pd.read_csv(i, names=header_list)\n",
    "    df1 = df['Review'].str.cat(sep=' ')\n",
    "    review = df['Review'].str.cat(sep=' ')\n",
    "    names = df['Name'][0]\n",
    "    geolocation = df['Geolocation'][0]\n",
    "    data = [names,review, geolocation]\n",
    "    atm_data.append(data)\n",
    "    \n",
    "labels = ['Name','Review','Geolocation'] \n",
    "data_result = pd.DataFrame.from_records(atm_data, columns=labels)\n",
    "data_result.to_csv('test2022.csv',encoding='utf-8-sig') #ผลลัพธ์ที่ได้ครับ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing CSV file\n",
    "df = pd.read_csv(\"test2022.csv\") #เลือกข้อมูล\n",
    "## Applying Compund score\n",
    "polarity_scores = df[\"Review\"].astype(\"str\").apply(compound_score) #ตรง df[\"Review\"] ถ้า column ที่เก็บข้อมูลรีวิวไม่ใช่ชื่อนี้ก็เปลี่ยนด้วย\n",
    "df[\"Sentiment_Score\"] = polarity_scores\n",
    "## Applying Sentiment\n",
    "df[\"Sentiment\"] = df[\"Sentiment_Score\"].apply(sentiment)\n",
    "\n",
    "## Saving preprocessed file \n",
    "df.to_csv(\"test_merge_sentiments.csv\",index=False, encoding='utf-8') #อย่าลืมเปลี่ยนที่เก็บผลลัพธ์และตั้งชื่อใหม่\n",
    "df.Sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "eb4f3c2745d5e24f01fa2041e6a45ad2b07924bca0b56c56c7d2e71a35823404"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
