{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.0 64-bit' requires ipykernel package.\n",
      "Run the following command to install 'ipykernel' into the Python environment. \n",
      "Command: 'c:/Users/attawut/AppData/Local/Programs/Python/Python39/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import emoji\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "def remove_url(txt):\n",
    "    url = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url.sub(r'',txt)\n",
    "\n",
    "def remove_html(txt):\n",
    "    html=re.compile(r'<.*?>')\n",
    "    return html.sub(r'',txt)\n",
    "\n",
    "# U+1F970\n",
    "def remove_emoji(txt):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', txt)\n",
    "def remove(emoji):\n",
    "    em = re.compile(r\"🥰\")\n",
    "    return em.sub(r\"\",emoji)\n",
    "def remove_blank_space(text):\n",
    "    return re.sub(\"\\s\\s+\" , \" \", text)\n",
    "def remove_blank2(text):\n",
    "    text = text.strip()\n",
    "    return text\n",
    "def remove_all(ReviewText):\n",
    "    ReviewText = ReviewText.replace(\"(<br/>)\", \"\")\n",
    "    ReviewText = ReviewText.replace('(<a).*(>).*(</a>)', '')\n",
    "    ReviewText = ReviewText.replace('(&amp)', '')\n",
    "    ReviewText = ReviewText.replace('(&gt)', '')\n",
    "    ReviewText = ReviewText.replace('(&lt)', '')\n",
    "    ReviewText = ReviewText.replace('(\\xa0)', ' ') \n",
    "    ReviewText = ReviewText.replace(r'http[s]?://(?:[a-z]|[0-9]|[$-_@.&amp;+]|[!*\\(\\),]|(?:%[0-9a-f][0-9a-f]))+', ' ') \n",
    "    return ReviewText\n",
    "\n",
    "from wordcloud import STOPWORDS\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "s_words= list(stopwords.words('english'))\n",
    "stop_words = list(STOPWORDS)+ [\"what\", \"us\", \"this\",\"well\",\"there\",\"much\",\"us\",\"and\",\"you're\",\"in\",\"where\",\"when\",\"just\",\"how\",\"is\",\"ha\",\"re\",\"are\"\n",
    "                              \"hi\",\"aren't\", 'couldn','could','couldnt',\"couldn't\",'did','had','have','must','does','should','was',\"it's\"\n",
    "                               \"didn't\", \"doesn't\", \"don't\", \"hadn't\", \"hasn't\", \"haven't\", \"isn't\", 'let', 'll',\"may\",'were','is','has','must',\n",
    "                               'mustn', 'rt', 'shan', 'shouldn', 'wasn', 'weren', 'won', 'wouldn','realli','now','got','man','people','a',\n",
    "                               'becaus','caus',\"one\",\"im\",\"guy\",\"someone\",\"two\",\"nearby\",\"i\",\"he's\",\"she's\",\"we\",\"it\",\"they\",\"wouldn’t\",\"i've\",\n",
    "                               'aren', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'sdidn', 've',\"will\",\"restaurant\"]\n",
    "\n",
    "\n",
    "\n",
    "def remove_stopwords(txt):\n",
    "    \n",
    "    sentence = []\n",
    "    s = \"\"\n",
    "    for word in txt.split():    \n",
    "        if(word not in stop_words):      \n",
    "            sentence.append(word)\n",
    "            s = ' '.join(sentence)\n",
    "    return s\n",
    "\n",
    "def strip_emoji(text):\n",
    "\n",
    "    print(emoji.emoji_count(text))\n",
    "\n",
    "    new_text = re.sub(emoji.get_emoji_regexp(), r\"\", text)\n",
    "\n",
    "    return new_text\n",
    "\n",
    "## Creating sentimental polarity \n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "def compound_score(txt):\n",
    "    return analyzer.polarity_scores(txt)[\"compound\"]\n",
    "\n",
    "## Sentiments\n",
    "def sentiment(score):\n",
    "    emotion = \"\"\n",
    "    if score >= 0.5:\n",
    "        emotion = \"Positive\"\n",
    "    elif score <= -0.5:\n",
    "        emotion = \"Negative\"\n",
    "    else:\n",
    "        emotion = \"Neutral\"\n",
    "    return emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import words\n",
    "from stop_words import get_stop_words\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "\n",
    "atm_data = []\n",
    "header_list = [\"1\", \"2\", \"3\",\"4\",\"5\"]\n",
    "# create a Path instance and filter for only csv files\n",
    "files = Path(\"input_data/\").rglob(\"*.csv\") #Input Folder ที่ทำการ Rename เรียบร้อยแล้ว\n",
    "\n",
    "for i in files:\n",
    "    df = pd.read_csv(i, names=header_list)\n",
    "    df1 = df['Review'].str.cat(sep='')\n",
    "    df2 = strip_emoji(df1)\n",
    "    df3 = clean_msg(df2)\n",
    "    df4 = split_word(df3)\n",
    "    df5 = listToString(df4)\n",
    "    result = get_sentiment(df5)\n",
    "    names = i.name\n",
    "    results = result\n",
    "    data = [names, results]\n",
    "    atm_data.append(data)\n",
    "    print(names)\n",
    "    \n",
    "labels = ['Name','result'] \n",
    "data_result = pd.DataFrame.from_records(atm_data, columns=labels)\n",
    "data_result.to_csv('tripadvisor_restaurant_sentiment_28092021.csv',encoding='utf-8-sig') #ผลลัพธ์ที่ได้ครับ\n",
    "print(\"Finish!!\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Review = df.Review.apply(remove_url) #ใช้ method เลือก column ที่เก็บข้อมูลรีวิว\n",
    "df.Review = df.Review.apply(remove_html) #ใช้ method เลือก column ที่เก็บข้อมูลรีวิว\n",
    "df.Review = df.Review.apply(remove_emoji) #ใช้ method เลือก column ที่เก็บข้อมูลรีวิว\n",
    "df.Review = df.Review.apply(remove) #ใช้ method เลือก column ที่เก็บข้อมูลรีวิว\n",
    "df.Review = df.Review.apply(remove_blank_space) #ใช้ method เลือก column ที่เก็บข้อมูลรีวิว\n",
    "df.Review = df.Review.apply(remove_blank2) #ใช้ method เลือก column ที่เก็บข้อมูลรีวิว\n",
    "df.Review = df.Review.apply(remove_all) #ใช้ method เลือก column ที่เก็บข้อมูลรีวิว\n",
    "df.Review = df.Review.map(remove_stopwords) #ใช้ method เลือก column ที่เก็บข้อมูลรีวิว\n",
    "df.Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "atm_data = []\n",
    "header_list = [\"1\", \"2\", \"3\",\"4\",\"5\"]\n",
    "# create a Path instance and filter for only csv files\n",
    "files = Path(\"input_data/\").rglob(\"*.csv\") #Input Folder ที่ทำการ Rename เรียบร้อยแล้ว"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_data\\mining_2fortheroadหาดจอมเทยนไทย.csv\n",
      "input_data\\mining_2สกายพทยารอคเกตบอลไทย.csv\n",
      "input_data\\mining_313TrainingStudioพทยาไทย.csv\n",
      "input_data\\mining_4TBarพทยาไทย.csv\n",
      "input_data\\mining_7สปามาชาลกซรพทยาไทย.csv\n",
      "input_data\\mining_808Clubพทยาไทย.csv\n",
      "input_data\\mining_AbbesBarพทยาไทย.csv\n",
      "input_data\\mining_AdventureDiversPattayaพทยาไทย.csv\n",
      "input_data\\mining_AIRPORTELsMakepeopleTravelLightAnywhereพทยาไทย.csv\n",
      "input_data\\mining_AisawanSpaพทยาไทย.csv\n",
      "input_data\\mining_ALaCampagneเมองชลบรไทย.csv\n",
      "input_data\\mining_AmazonFishingParkPattayaพทยาไทย.csv\n",
      "input_data\\mining_AmburayaSpaพทยาไทย.csv\n",
      "input_data\\mining_AquanautsDiveCenterพทยาไทย.csv\n",
      "input_data\\mining_AREEMassageพทยาไทย.csv\n",
      "input_data\\mining_AromdeeMassageพทยาไทย.csv\n",
      "input_data\\mining_ARTmassageพทยาไทย.csv\n",
      "input_data\\mining_ArtStreetPattayaพทยาไทย.csv\n",
      "input_data\\mining_ArttoArtGalleryพทยาไทย.csv\n",
      "input_data\\mining_AshtangaYogaPattayaพทยาไทย.csv\n"
     ]
    }
   ],
   "source": [
    "for i in files:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "eb4f3c2745d5e24f01fa2041e6a45ad2b07924bca0b56c56c7d2e71a35823404"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
